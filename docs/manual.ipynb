{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2b64c82",
   "metadata": {},
   "source": [
    "# CBM Power — User Manual\n",
    "\n",
    "**Computational Behavioral/Brain Modeling (CBM) — Power & Sample Size**\n",
    "\n",
    "This notebook introduces a method for computing power in computational modeling studies that involve **model selection among multiple competing models**, and shows how to use the Python API (`Power`, `SampleSize`, `Config`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80b9312",
   "metadata": {},
   "source": [
    "## 1. Motivation & key ideas\n",
    "\n",
    "- **Goal.** Introduce a principled method to compute statistical power in computational modeling studies with model selection across a set of models.\n",
    "- **Insight.** When the number of competing models increases, the power of model selection decreases (it becomes harder to reliably identify the best model).\n",
    "- **Significance.** This factor has been largely neglected in the field; as a result, many studies may be underpowered.\n",
    "- **Key idea:** Treat model comparison as a stochastic process arising from finite data and uncertainty about population-level generative parameters. Use simulation to estimate the probability that the *correct* model wins by an exceedance-probability threshold.\n",
    "\n",
    "\n",
    "### Reference\n",
    "If you use this code or method, please cite:\n",
    "> Piray, Payam, “Addressing low statistical power in computational modeling studies in psychology and neuroscience”, *Nature Human Behaviour*, 2025.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a0bf76",
   "metadata": {},
   "source": [
    "## 2. Setup\n",
    "\n",
    "Install the library (editable mode is fine during development):\n",
    "\n",
    "```bash\n",
    "pip install -e .\n",
    "```\n",
    "\n",
    "Then import the API:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec21e661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal imports from the package\n",
    "# from cbm_power import Power, SampleSize, Config\n",
    "\n",
    "# For this demo notebook we avoid heavy runs and just show usage examples.\n",
    "print(\"Ready to use: Power, SampleSize, Config\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b6882f",
   "metadata": {},
   "source": [
    "## 3. Computing power for a given sample size & model space\n",
    "\n",
    "The main function of the `Power` class is **`compute_power`**.  \n",
    "It returns **two** objects:\n",
    "1. `estimated_power` (float), and  \n",
    "2. a `result` object containing detailed fields (posterior parameters, exceedance probabilities, etc.).\n",
    "\n",
    "**Minimal configuration** requires only:\n",
    "- `num_participants` (sample size, **N**), and\n",
    "- `num_models` (size of the model space, **K**)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2507a17c",
   "metadata": {},
   "source": [
    "### Example (pseudo-code)\n",
    "```python\n",
    "from cbm_power import Power\n",
    "\n",
    "# Example (for a faster experiment, decrease num_sim to 1000)\n",
    "pwr = Power()\n",
    "estimated_power, result = pwr.compute_power(\n",
    "    num_participants=410,\n",
    "    num_models=10,\n",
    "    num_sim = 10_000\n",
    ")\n",
    "print(f\"Power ≈ {estimated_power:.2f}\")  # two-decimal display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f965b9",
   "metadata": {},
   "source": [
    "`compute_power(...) -> (estimated_power, result)`\n",
    "\n",
    "- **`estimated_power` (float):** Mean probability (over simulations) that the selected best model's exceedance probability passes the null threshold for the acceptable false positive rate.\n",
    "\n",
    "- **`result` (a dataclass object):**\n",
    "  - `exceedance_threshold` *(float)* — the threshold chosen under the null to control false positives at `false_positive_acceptable`.\n",
    "  - `false_positive_rate` *(float)* — measured false positive rate at the chosen threshold (should be ≤ specified tolerance).\n",
    "  - `posterior_parameters` *(array)* — group-level Dirichlet parameters used to compute exceedance probabilities.\n",
    "  - `exceedance_prob` *(array)* — per-simulation exceedance probabilities across models.\n",
    "  - `population_samples` *(array)* — sampled population-level multinomial probabilities (rows where model 1 is best).\n",
    "  - **Configuration snapshot (for reproducibility)** — e.g. `num_sim`, `num_samples_4ep`, `max_iter`, and any true/target parameters used internally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f75ea0",
   "metadata": {},
   "source": [
    "## 4. Sample-Size optimization\n",
    "\n",
    "`SampleSize.run()` performs a 4-stage optimization of sample size, N:\n",
    "1. **Stage 0:** Initialization via a fast procedure that does not compute exceedance probabilities.\n",
    "2. **Stages 1–2:** Bayesian optimization (BO) over N using repeated evaluations of power (using ax-platform package).\n",
    "3. **Stage 3:** Exhaustive downward search from the best candidate to find the smallest N that still achieves the target power at two-decimal resolution.\n",
    "\n",
    "Since optimization can be complex, this process may take some time.\n",
    "\n",
    "### Example (pseudo-code)\n",
    "```python\n",
    "from cbm_power import SampleSize, Config\n",
    "\n",
    "cfg = Config(\n",
    "    num_models=5,\n",
    "    false_positive_acceptable=0.05,\n",
    ")\n",
    "ss = SampleSize(cfg)\n",
    "cbm = ss.compute_sample_size()   # Runs all 4 stages; saves JSON + log automatically\n",
    "# optinal: filename_stem=\"my_run\"  # controls my_run.json / my_run.log\n",
    "# cbm = ss.compute_sample_size(save_path=filename_stem)   # Runs all 4 stages; saves JSON + log automatically\n",
    "\n",
    "print(\"Optimized N:\", cbm.output.sample_size)  # dataclass field access\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89816d9",
   "metadata": {},
   "source": [
    "## 5. Configuration guide\n",
    "\n",
    "`Config` fields (common):\n",
    "- `num_models` *(int, required)* — size of the model space (K).\n",
    "- `rng` *(int or numpy.random.Generator)* — random seed or RNG for reproducibility. Optional; defaults to seed 0.\n",
    "- `prior_parameter` *(float)* — Dirichlet prior strength (default 1.0).\n",
    "- `false_positive_acceptable` *(float)* — acceptable level for determining the exceedance threshold under the null (default 0.05).\n",
    "- `desired_power` *(float)* — target power for optimization (default 0.80).\n",
    "- `optimize_true` *(bool)* — if `True`, attempt to find a Dirichlet parameter matching `target_effect_size` (default `False`).\n",
    "- `target_effect_size` *(float or None)* — target mean effect size (the population-level difference between probabilities of the best and second-best models) used when optimizing the true distribution. If set to None and optimize_true is True, it defaults to 0.3, which is considered a medium effect size for two models (per Cohen). Note that for studies with more than two competing models, this value may correspond to a large or even very large effect size.\n",
    "- `true_parameter` *(float or None)* — if given and `optimize_true=False`, use this value for the population Dirichlet; otherwise it can be ignored and optimized (default 1).\n",
    "\n",
    "Per-stage arrays (length 4):\n",
    "- `max_iter` — maximum Bayesian optimization iterations per stage (default `[50, 100, 100, None]`).\n",
    "- `tol` — stop tolerance per stage (default `[0.05, 0.02, 0.015, 0.015]`).\n",
    "- `replicates` — number of repetitions with different seeds per trial (default `[1, 5, 20, 10]`).\n",
    "- `num_sim` — number of simulations scenarios (default `[10000, 1000, 1000, 5000]`).\n",
    "- `num_sim_4ep` — number of samples for computing exceedance probability (default `[10000, 1000, 1000, 5000]`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75feaf1",
   "metadata": {},
   "source": [
    "## 6. Reproducibility & saved artifacts\n",
    "\n",
    "- **JSON**: Full results (initialization, BO stages, exhaustive trials, configuration snapshot).\n",
    "- **Log**: Console-like trace of trials and stage summaries.\n",
    "\n",
    "If a filename stem is provided in `Config`, outputs will be saved as `<stem>.json` and `<stem>.log`. If **not provided**, the library defaults to timestamped filenames like `cbm_YYYYMMDD_HHMMSS.json`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dd7d5e",
   "metadata": {},
   "source": [
    "## 7. Troubleshooting & performance Tips\n",
    "\n",
    "- **Performance / Memory.** Two knobs control runtime and memory:\n",
    "  - `num_sim`: number of population scenarios sampled for estimating power.\n",
    "  - `num_samples_4ep`: number of samples per scenario for estimating exceedance probabilities.\n",
    "\n",
    "  Reduce these to speed up experiments. In this case, run multiple seeds and compute mean power with error bars (e.g., standard error or a confidence interval). On a typical laptop (e.g., macOS with 16 GB RAM), `num_sim=10_000` and `num_samples_4ep=10_000` works successfully.\n",
    "\n",
    "- **Flat objective regions.** When power is rounded to two decimals, many N values can look equivalent. The optimizer handles ties, and the exhaustive final stage ensures the smallest adequate N is returned.\n",
    "\n",
    "- **Numerical warnings.** Gaussian-process-based BO may add small jitter during optimization. This is generally harmless and indicates numerical stabilization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2a89f2",
   "metadata": {},
   "source": [
    "## 8. Interpreting saved outputs\n",
    "\n",
    "`SampleSize.compute_sample_size()` creates two artifacts in the working directory (unless a file_path is given in SampleSize.compute_sample_size(save_path=file_path)):\n",
    "\n",
    "- `cbm_YYYYMMDD_HHMMSS.json` — a full, JSON-serializable record of:\n",
    "  - Final output (`sample_size`, `power` mean and `dispersion`, final replicate vector)\n",
    "  - Stage-by-stage results (including the exhaustive Stage 3 trials)\n",
    "  - Config used (without non-serializable RNG objects)\n",
    "  - Artifact paths\n",
    "- `cbm_YYYYMMDD_HHMMSS.log` — a mirror of console output (trials, early stops, exhaustive search trace)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
